{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58cfb2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2498977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "state: [-0.01462386 -0.03937347  0.0003041  -0.03702828]\n",
      "\n",
      "next_state: [-0.01541133 -0.23449978 -0.00043646  0.2557506 ] reward: 1.0\n",
      "\n",
      "next_state: [-0.02010132 -0.4296155   0.00467855  0.5482958 ] reward: 1.0\n",
      "\n",
      "next_state: [-0.02869364 -0.6248029   0.01564446  0.8424491 ] reward: 1.0\n",
      "\n",
      "next_state: [-0.04118969 -0.8201348   0.03249345  1.1400105 ] reward: 1.0\n",
      "\n",
      "next_state: [-0.05759239 -1.0156661   0.05529366  1.4427041 ] reward: 1.0\n",
      "\n",
      "next_state: [-0.07790571 -1.2114235   0.08414774  1.7521393 ] reward: 1.0\n",
      "\n",
      "next_state: [-0.10213418 -1.4073936   0.11919053  2.0697646 ] reward: 1.0\n",
      "\n",
      "next_state: [-0.13028204 -1.6035088   0.16058582  2.3968096 ] reward: 1.0\n",
      "\n",
      "next_state: [-0.16235223 -1.7996314   0.208522    2.734218  ] reward: 1.0\n",
      "\n",
      "next_state: [-0.19834486 -1.9955337   0.26320636  3.0825682 ] reward: 1.0\n",
      "\n",
      "Epochs: 10\n"
     ]
    }
   ],
   "source": [
    "def choose_action(state):\n",
    "    angle, x, pole_velocity, xx = state\n",
    "    if angle < 0:\n",
    "        return 0  # move left\n",
    "    else:\n",
    "        return 1  # move right\n",
    "\n",
    "\n",
    "# Create the CartPole environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Reset the environment and get the initial state\n",
    "state, _ = env.reset()\n",
    "print(\"\\nstate:\", state)\n",
    "\n",
    "# Run the game until completion\n",
    "done = False\n",
    "epochs = 0\n",
    "while not done:\n",
    "    # Choose an action based on the current state\n",
    "    action = choose_action(state)  # 0 or 1\n",
    "\n",
    "    # Take the chosen action and get the next state and reward\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    print(\"\\nnext_state:\", next_state, \"reward:\", reward)\n",
    "\n",
    "    # Update the current state\n",
    "    state = next_state\n",
    "\n",
    "    epochs += 1\n",
    "\n",
    "print(\"\\nEpochs:\", epochs)\n",
    "\n",
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c650245a",
   "metadata": {},
   "source": [
    "# env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288f1b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b830f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03296729,  0.01190647, -0.00095286, -0.01161914], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85e01a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b28a405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'env': <OrderEnforcing<PassiveEnvChecker<CartPoleEnv<CartPole-v1>>>>,\n",
       " '_action_space': None,\n",
       " '_observation_space': None,\n",
       " '_reward_range': None,\n",
       " '_metadata': None,\n",
       " '_max_episode_steps': 500,\n",
       " '_elapsed_steps': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2274016f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'render_modes': ['human', 'rgb_array'], 'render_fps': 50}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d109f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9962ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-inf, inf)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac59cf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnvSpec(id='CartPole-v1', entry_point='gym.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=475.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CartPole', version=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec  # max_episode_steps=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c74dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# Define the Q-learning hyperparameters\n",
    "alpha = 0.1  # learning rate\n",
    "gamma = 0.99  # discount factor\n",
    "epsilon = 0.1  # exploration rate\n",
    "num_episodes = 10000  # number of episodes to run\n",
    "max_steps = 500  # maximum number of steps per episode\n",
    "\n",
    "# Create the CartPole environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Initialize the Q-table with zeros\n",
    "num_states = (1,) * env.observation_space.shape[0]\n",
    "num_actions = env.action_space.n\n",
    "Q = np.zeros(num_states + (num_actions,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45b52c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5842c985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8db4da23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[0., 0.]]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a91f721",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/47/6nl3w5n91ql2msklj729p6cr0000gn/T/ipykernel_8708/128703367.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mstate_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# Loop over episodes\n",
    "for episode in range(num_episodes):\n",
    "    # Reset the environment and get the initial state\n",
    "    state, _ = env.reset()\n",
    "    state = state[0]  # Convert the state tuple to a 1D numpy array\n",
    "\n",
    "    # Loop over steps\n",
    "    for step in range(max_steps):\n",
    "        # Choose an action using epsilon-greedy policy\n",
    "        if np.random.uniform() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            state_index = np.argmax(Q[state])\n",
    "            action = state_index\n",
    "\n",
    "        # Take the chosen action and get the next state and reward\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "        # Update the Q-value using Q-learning formula\n",
    "        next_state_index = np.argmax(Q[next_state])\n",
    "        Q[state][action] += alpha * (reward + gamma * np.max(Q[next_state_index]) - Q[state][action])\n",
    "\n",
    "        # Update the current state\n",
    "        state = next_state[0]  # Convert the state tuple to a 1D numpy array\n",
    "\n",
    "        # If the game is completed, end the episode\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Decay epsilon after each episode\n",
    "    epsilon *= 0.99\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n",
    "\n",
    "# Print the final Q-table\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85f5aa49",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Box' object has no attribute 'n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/47/6nl3w5n91ql2msklj729p6cr0000gn/T/ipykernel_8708/1772864298.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnb_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnb_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mqtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Box' object has no attribute 'n'"
     ]
    }
   ],
   "source": [
    "nb_states = env.observation_space.n\n",
    "nb_actions = env.action_space.n\n",
    "\n",
    "qtable = np.zeros((nb_states, nb_actions))\n",
    "\n",
    "# Let's see how it looks\n",
    "print('\\nQ-table =')\n",
    "print(qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf74df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
