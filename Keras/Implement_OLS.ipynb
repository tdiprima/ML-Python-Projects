{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Regression\n",
    "\n",
    "OLS regression stands for **\"Ordinary Least Squares\"** regression, which is a type of statistical analysis that helps us understand how one variable affects another. \n",
    "\n",
    "Imagine you have a set of data that contains two variables, like the amount of **time** someone **studies** and the **grade** they get on a test. OLS regression helps us figure out if there's a **relationship** between these two variables by **drawing a line** through the data that best fits the pattern.\n",
    "\n",
    "This line is called the **\"regression line,\"** and it tells us how much the grade on the test changes for every extra hour someone studies. OLS regression calculates this line by finding the line that minimizes the distance between each data point and the line. \n",
    "\n",
    "So, in short, OLS regression is a way to figure out **if two things are related**, and **how much** they're related by drawing a line that best fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns  # https://seaborn.pydata.org/tutorial.html\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn has datasets too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conveniently, it returns a pandas dataframe\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 1), (150,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = iris[[\"petal_length\"]]  # predictor\n",
    "y = iris[\"petal_width\"]  # response\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodels gives R-like statistical output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "petal_width vs:\n",
      "petal_length\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            petal_width   R-squared:                       0.946\n",
      "Model:                            OLS   Adj. R-squared:                  0.944\n",
      "Method:                 Least Squares   F-statistic:                     629.8\n",
      "Date:                Wed, 03 May 2023   Prob (F-statistic):           1.54e-90\n",
      "Time:                        10:18:53   Log-Likelihood:                 46.705\n",
      "No. Observations:                 150   AIC:                            -83.41\n",
      "Df Residuals:                     145   BIC:                            -68.36\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const            0.2533      0.127      1.993      0.048       0.002       0.504\n",
      "petal_length     0.2319      0.053      4.393      0.000       0.128       0.336\n",
      "sepal_length    -0.0017      0.044     -0.038      0.969      -0.089       0.086\n",
      "setosa          -0.3378      0.097     -3.501      0.001      -0.529      -0.147\n",
      "versicolor       0.0948      0.055      1.717      0.088      -0.014       0.204\n",
      "virginica        0.4963      0.097      5.090      0.000       0.304       0.689\n",
      "==============================================================================\n",
      "Omnibus:                        6.224   Durbin-Watson:                   1.736\n",
      "Prob(Omnibus):                  0.045   Jarque-Bera (JB):                9.603\n",
      "Skew:                          -0.112   Prob(JB):                      0.00822\n",
      "Kurtosis:                       4.219   Cond. No.                     2.89e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 9.39e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# OLS linear regression\n",
    "model = sm.OLS(y, X)  # Note the swap of X and y\n",
    "\n",
    "results = model.fit()\n",
    "\n",
    "print(\"\\npetal_width vs:\\npetal_length\\n\", results.summary())  # Looks better, maybe\n",
    "# results.summary()  # But I want the formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## R-squared (uncentered)\n",
    "\n",
    "\"R-squared (uncentered)\" refers to a variant of the R-squared statistic that is calculated using the **uncentered total sum of squares** instead of the **centered total sum of squares.** \n",
    "\n",
    "The R-squared statistic is a measure of **how much of the variability** in the response variable (i.e., the dependent variable) is explained by the regression model. It is a number between 0 and 1, with **higher values** indicating a better fit between the model and the data.\n",
    "\n",
    "The **standard R-squared statistic** (also known as the \"centered\" R-squared) is calculated using the centered total sum of squares, which is the sum of squared deviations of the observed response values from their mean.\n",
    "\n",
    "This means that the R-squared value represents the proportion of the total variability in the response variable that is explained by the regression model after accounting for the mean.\n",
    "\n",
    "In contrast, the **uncentered R-squared** uses the uncentered total sum of squares, which is the sum of squared deviations of the observed response values from 0 (i.e., **without subtracting the mean**).\n",
    "\n",
    "This means that the uncentered R-squared value represents the proportion of the total variability in the response variable that is explained by the regression model without accounting for the mean.\n",
    "\n",
    "The uncentered R-squared can be useful in some cases where the mean of the response variable is not relevant or not meaningful. However, the centered R-squared is more commonly used and provides a more comprehensive measure of the goodness of fit of the model. In general, it is important to interpret R-squared in the context of the specific dataset and research question at hand.\n",
    "\n",
    "\n",
    "## Where is the intercept info?\n",
    "\n",
    "In the code below, the intercept info is included in the **first column of the `X`** matrix, which is generated by the `np.vander()` function call. \n",
    "\n",
    "The **`np.vander()`** function **adds a column of ones** to the input `X` variable, creating a new matrix with two columns.\n",
    "\n",
    "The **first column** of this new matrix represents the **intercept.**\n",
    "\n",
    "The **second column** represents the original `X` variable (i.e., **petal length** in this case).\n",
    "\n",
    "By passing the `X` and `y` variables to the `sm.OLS()` function and fitting the linear regression model, the resulting summary printed by `print(results.summary())` will include **information** about the intercept, including the estimated coefficient value, standard error, t-value, and p-value. \n",
    "\n",
    "You can find the intercept info under the **\"coef\"** column of the \"OLS Regression Results\" table printed to the console, which will have a row with the label **\"const\"** representing the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "petal_width vs:\n",
      "x1, const\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            petal_width   R-squared:                       0.927\n",
      "Model:                            OLS   Adj. R-squared:                  0.927\n",
      "Method:                 Least Squares   F-statistic:                     1882.\n",
      "Date:                Wed, 03 May 2023   Prob (F-statistic):           4.68e-86\n",
      "Time:                        10:16:45   Log-Likelihood:                 24.796\n",
      "No. Observations:                 150   AIC:                            -45.59\n",
      "Df Residuals:                     148   BIC:                            -39.57\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.4158      0.010     43.387      0.000       0.397       0.435\n",
      "const         -0.3631      0.040     -9.131      0.000      -0.442      -0.285\n",
      "==============================================================================\n",
      "Omnibus:                        5.765   Durbin-Watson:                   1.455\n",
      "Prob(Omnibus):                  0.056   Jarque-Bera (JB):                5.555\n",
      "Skew:                           0.359   Prob(JB):                       0.0622\n",
      "Kurtosis:                       3.611   Cond. No.                         10.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X = iris[\"petal_length\"]  # float64, shape (150,)\n",
    "\n",
    "X = np.vander(X, 2)  # Shape (150, 2) (Add a column for the intercept.)\n",
    "\n",
    "y = iris[\"petal_width\"]  # float64, shape (150,)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "\n",
    "results = model.fit()\n",
    "\n",
    "# results.summary()\n",
    "print(\"\\npetal_width vs:\\nx1, const\\n\", results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Petal_width = 0.41 - 0.36* (petal_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear regression\n",
    "\n",
    "More than one predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[[\"petal_length\", \"sepal_length\"]]  # predictors\n",
    "y = iris[\"petal_width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "petal_width vs:\n",
      "const, petal_length, sepal_length\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            petal_width   R-squared:                       0.929\n",
      "Model:                            OLS   Adj. R-squared:                  0.928\n",
      "Method:                 Least Squares   F-statistic:                     962.1\n",
      "Date:                Wed, 03 May 2023   Prob (F-statistic):           3.60e-85\n",
      "Time:                        10:16:45   Log-Likelihood:                 26.792\n",
      "No. Observations:                 150   AIC:                            -47.58\n",
      "Df Residuals:                     147   BIC:                            -38.55\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           -0.0090      0.182     -0.049      0.961      -0.369       0.351\n",
      "petal_length     0.4494      0.019     23.205      0.000       0.411       0.488\n",
      "sepal_length    -0.0822      0.041     -1.992      0.048      -0.164      -0.001\n",
      "==============================================================================\n",
      "Omnibus:                        6.657   Durbin-Watson:                   1.414\n",
      "Prob(Omnibus):                  0.036   Jarque-Bera (JB):                6.663\n",
      "Skew:                           0.386   Prob(JB):                       0.0357\n",
      "Kurtosis:                       3.685   Cond. No.                         80.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Note the swap of X and y\n",
    "X = iris[[\"petal_length\", \"sepal_length\"]]\n",
    "X = sm.add_constant(X)  # another way to add a constant row for an intercept\n",
    "\n",
    "y = iris[\"petal_width\"]\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# results.summary()\n",
    "print(\"\\npetal_width vs:\\nconst, petal_length, sepal_length\\n\", results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species  setosa  \\\n",
       "0           5.1          3.5           1.4          0.2  setosa       1   \n",
       "1           4.9          3.0           1.4          0.2  setosa       1   \n",
       "2           4.7          3.2           1.3          0.2  setosa       1   \n",
       "3           4.6          3.1           1.5          0.2  setosa       1   \n",
       "4           5.0          3.6           1.4          0.2  setosa       1   \n",
       "\n",
       "   versicolor  virginica  \n",
       "0           0          0  \n",
       "1           0          0  \n",
       "2           0          0  \n",
       "3           0          0  \n",
       "4           0          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For dummies\n",
    "dummies = pd.get_dummies(iris[\"species\"])\n",
    "\n",
    "# Add to the original dataframe\n",
    "iris = pd.concat([iris, dummies], axis=1)  # assign numerical values to the different species\n",
    "\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## AC⚡️BC \n",
    "\n",
    "### You would be inclined to choose the model that had the lower AIC or BIC value.\n",
    "\n",
    "**AIC:** \"Akaike Information Criterion\"\n",
    "\n",
    "**BIC:** \"Bayesian Information Criterion\"\n",
    "\n",
    "They are both statistical measures that help in model selection when comparing multiple regression models.\n",
    "\n",
    "Both AIC and BIC provide a way to **compare the goodness-of-fit** of different models that have different numbers of parameters.\n",
    "\n",
    "These measures take into account both the **quality of the fit** of the model to the data (i.e., **how well** it explains the data), as well as the **complexity** of the model (i.e., **how many** parameters it has). \n",
    "\n",
    "AIC and BIC are calculated based on the **log-likelihood function** of the model and the number of parameters in the model.\n",
    "\n",
    "A **lower value** of AIC or BIC indicates a **better fit** with a simpler model, and the model with the lowest AIC or BIC value is typically considered to be the best-fitting model.\n",
    "\n",
    "In the summary table, you will see both AIC and BIC listed under the **\"Information Criteria\"** section. The values of AIC and BIC can be used to compare different models with the same data and to determine which model is the most appropriate for a given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "petal_width vs:\n",
      "const, petal_length, sepal_length, setosa...?                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            petal_width   R-squared:                       0.946\n",
      "Model:                            OLS   Adj. R-squared:                  0.944\n",
      "Method:                 Least Squares   F-statistic:                     629.8\n",
      "Date:                Wed, 03 May 2023   Prob (F-statistic):           1.54e-90\n",
      "Time:                        10:16:45   Log-Likelihood:                 46.705\n",
      "No. Observations:                 150   AIC:                            -83.41\n",
      "Df Residuals:                     145   BIC:                            -68.36\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const            0.2533      0.127      1.993      0.048       0.002       0.504\n",
      "petal_length     0.2319      0.053      4.393      0.000       0.128       0.336\n",
      "sepal_length    -0.0017      0.044     -0.038      0.969      -0.089       0.086\n",
      "setosa          -0.3378      0.097     -3.501      0.001      -0.529      -0.147\n",
      "versicolor       0.0948      0.055      1.717      0.088      -0.014       0.204\n",
      "virginica        0.4963      0.097      5.090      0.000       0.304       0.689\n",
      "==============================================================================\n",
      "Omnibus:                        6.224   Durbin-Watson:                   1.736\n",
      "Prob(Omnibus):                  0.045   Jarque-Bera (JB):                9.603\n",
      "Skew:                          -0.112   Prob(JB):                      0.00822\n",
      "Kurtosis:                       4.219   Cond. No.                     2.89e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 9.39e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "X = iris[[\"petal_length\", \"sepal_length\", \"setosa\", \"versicolor\", \"virginica\"]]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "y = iris[\"petal_width\"]\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(\"\\npetal_width vs:\\nconst, petal_length, sepal_length, setosa...?\", results.summary())\n",
    "# results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "intercept:\n",
      " 0.3376683161818015\n",
      "\n",
      "coef:\n",
      " [ 0.          0.23192122 -0.00169337 -0.42226013  0.01039913  0.411861  ]\n"
     ]
    }
   ],
   "source": [
    "# Fit the linear model using sklearn\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "results = model.fit(X, y)\n",
    "\n",
    "# Print the coefficients\n",
    "print(\"\\nintercept:\\n\", results.intercept_)\n",
    "print(\"\\ncoef:\\n\", results.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Results\n",
    "\n",
    "When you fit a linear regression model using the `model.fit()` function in Python, the resulting `results` object contains several attributes that provide information about the fitted model.\n",
    "\n",
    "If you print `results.intercept_`, you will see the estimated intercept of the linear regression model. The intercept represents the value of the dependent variable when all independent variables are equal to zero. In the context of the linear regression model, the intercept is the point where the regression line crosses the y-axis.\n",
    "\n",
    "If you print `results.coef_`, you will see the estimated coefficients of the independent variables in the linear regression model. Each element of the `results.coef_` array corresponds to the estimated coefficient of one independent variable in the model. The coefficients represent the change in the dependent variable associated with a one-unit change in the corresponding independent variable, while holding all other variables constant.\n",
    "\n",
    "For example, if you fit a linear regression model with two independent variables, `x1` and `x2`, and print `results.intercept_` and `results.coef_`, you will see the estimated intercept and coefficients for the model. The intercept will represent the predicted value of the dependent variable when both `x1` and `x2` are equal to zero. The coefficients will represent the estimated change in the dependent variable associated with a one-unit increase in `x1` or `x2`, while holding the other variable constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
